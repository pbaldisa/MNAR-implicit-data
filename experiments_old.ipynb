{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "Most of the code in this repository is based on the code provided by the original article and is not my original work. I have only added some additional experiments and explanations. The original code can be found [here](https://github.com/usaito/unbiased-implicit-rec-real)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, I will be partially reproducing the experiments provided by the original researchers. The steps are as follows:\n",
    "* Train a model on the MovieLens 100k dataset\n",
    "* Plot and analyse the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model\n",
    "In this part, we will train a model using semi-synthetic data. It uses the MovieLens 100K dataset, that can be fond [here](https://grouplens.org/datasets/movielens/100k/). (Note that in this repository, I have only left the relevant files, and not the whole dataset.)\n",
    "\n",
    "This data contains five-star movie ratings and the ratings are MNAR. As the article states, to facilitate ground-truth evaluation against a fully known relevance and exposure parameters, we can create parameters as follows:\n",
    "1. Using Rating-based factorization we found an approximation of the true ratings as $R_{u,i} \\approx \\hat{R}_{u,i}$\n",
    "2. Using logistic matrix factorization we found an approximation of the true observations as $O_{u,i} \\approx \\hat{O}_{u,i}$ where $O_{u,i}$ is a binary variable representing whether the rating of (u,i) is observed or not (1 or 0, respectively). Thus, $\\hat{O}_{u,i} \\in (0,1)$ is the estimated probability of observing the rating of (u,i).\n",
    "3. We generate the ground-truth relevance and exposure parameters as follows:\n",
    "    $$ P(R_{u,i}=1) = \\sigma(\\hat{R}_{u,i}-\\epsilon) $$\n",
    "    $$ P(O_{u,i}=1) = (\\hat{O}_{u,i})^p $$\n",
    "    Where $\\sigma$ is the sigmoid function, $\\hat{R}_{u,i} \\in [1,5]$ is the approximation of the true ratings, $\\epsilon$ and $p$ are parameters, and $\\hat{O}_{u,i}$ is the ground-truth exposure.\n",
    "4. Following the probabilistic model explained in the article, we generate click variables as follows:\n",
    "    $$ O_{u,i} \\sim Bernoulli(P(O_{u,i}=1)) $$\n",
    "    $$ R_{u,i} \\sim Bernoulli(P(R_{u,i}=1)) $$\n",
    "    $$ Y_{u,i} = O_{u,i} \\cdot R_{u,i} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and generate data\n",
    "Using the function ```generate_sys_data()``` from data_generator.py, we can load and generate semi-synthetic data. The function takes the following arguments: ```eps, pow```. These parameters are used to generate the ground-truth relevance and exposure parameters, they correspond to $\\epsilon$ and $p$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import generate_sys_data\n",
    "data = generate_sys_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments and parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Args\n",
    "eps = 5.0\n",
    "pow_list = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "iters = 5\n",
    "# Model parameters\n",
    "dim = 10\n",
    "lam = 1e-5\n",
    "eta = 0.1\n",
    "batch_size = 12\n",
    "max_iters = 1000\n",
    "model_name = ['oracle', 'mf', 'rmf'] # Models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
